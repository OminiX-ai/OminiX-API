[package]
name = "ominix-api"
version = "0.1.0"
edition = "2021"
description = "OpenAI-compatible API server for OminiX-MLX models"
license = "MIT OR Apache-2.0"

[dependencies]
# HTTP Server
salvo = { version = "0.81.0", default-features = false, features = [
    "affix-state", "cors", "server", "http1", "http2", "websocket", "sse"
] }
tokio = { version = "1", features = ["full"] }
tokio-stream = { version = "0.1", features = ["sync"] }

# MLX inference
mlx-rs = { path = "../OminiX-MLX/mlx-rs", features = ["metal", "accelerate"] }
mlx-sys = { path = "../OminiX-MLX/mlx-rs/mlx-sys" }
mlx-rs-core = { path = "../OminiX-MLX/mlx-rs-core", features = ["convert"] }

# Model-specific crates
qwen3-mlx = { path = "../OminiX-MLX/qwen3-mlx" }
glm47-flash-mlx = { path = "../OminiX-MLX/glm-4.7-flash-mlx" }
funasr-mlx = { path = "../OminiX-MLX/funasr-mlx" }
funasr-qwen4b-mlx = { path = "../OminiX-MLX/funasr-qwen4b-mlx" }
gpt-sovits-mlx = { path = "../OminiX-MLX/gpt-sovits-mlx" }
flux-klein-mlx = { path = "../OminiX-MLX/flux-klein-mlx" }
zimage-mlx = { path = "../OminiX-MLX/zimage-mlx" }
moxin-vlm-mlx = { path = "../OminiX-MLX/moxin-vlm-mlx" }

# Tokenization
tokenizers = "0.22"

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Utilities
uuid = { version = "1", features = ["v4"] }
chrono = "0.4"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
eyre = "0.6"
hex = "0.4"
base64 = "0.22"
dirs = "6.0"

# Audio processing
hound = "3.5"

# Image processing
image = "0.25"

# HTTP client (for model downloads)
reqwest = { version = "0.12", features = ["blocking", "json"] }

[[bin]]
name = "ominix-api"
path = "src/main.rs"
