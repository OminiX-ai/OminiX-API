[package]
name = "ominix-api"
version = "0.1.0"
edition = "2021"
description = "OpenAI-compatible API server for OminiX-MLX models"
license = "MIT OR Apache-2.0"

[dependencies]
# HTTP Server
salvo = { version = "0.81.0", default-features = false, features = [
    "affix-state", "cors", "server", "http1", "http2"
] }
tokio = { version = "1", features = ["full"] }
tokio-stream = "0.1"
futures = "0.3"

# MLX inference
mlx-rs = { path = "../OminiX-MLX/mlx-rs", features = ["metal", "accelerate"] }
mlx-sys = { path = "../OminiX-MLX/mlx-sys" }
mlx-rs-core = { path = "../OminiX-MLX/mlx-rs-core" }

# Model-specific crates
qwen3-mlx = { path = "../OminiX-MLX/qwen3-mlx" }
funasr-mlx = { path = "../OminiX-MLX/funasr-mlx" }
gpt-sovits-mlx = { path = "../OminiX-MLX/gpt-sovits-mlx" }
flux-klein-mlx = { path = "../OminiX-MLX/flux-klein-mlx" }
zimage-mlx = { path = "../OminiX-MLX/zimage-mlx" }

# Model downloads
hf-hub = "0.4"

# Tokenization
tokenizers = "0.22"

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Utilities
uuid = { version = "1", features = ["v4"] }
chrono = "0.4"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
eyre = "0.6"
sha2 = "0.10"
hex = "0.4"
base64 = "0.22"

# Audio processing
hound = "3.5"

# Image processing
image = "0.25"

[[bin]]
name = "ominix-api"
path = "src/main.rs"
